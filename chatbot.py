import streamlit as st
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import google.generativeai as genai
import json
import datetime

# ==========================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==========================================
st.set_page_config(page_title="ê¸ˆìœµ ì¸ì‚¬ì´íŠ¸ AI Pro (Ver 4.6)", page_icon="ğŸ“ˆ", layout="wide")

# ==========================================
# [í•¨ìˆ˜] êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
# ==========================================
def get_sheet_client():
    if "gcp_service_account" not in st.secrets:
        st.error("Secrets ì„¤ì •(gcp_service_account)ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return None
    json_creds = dict(st.secrets["gcp_service_account"])
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_dict(json_creds, scope)
    client = gspread.authorize(creds)
    return client

# DB ìŠ¤í‚¤ë§ˆ (14ê°œ ì»¬ëŸ¼)
REQUIRED_HEADERS = [
    'video_id', 'url', 'title', 'channel_name', 'published_at', 
    'category', 'main_topic', 'key_arguments', 'evidence', 
    'implications', 'validity_check', 'sentiment', 'tags', 'full_summary'
]

def check_and_update_headers(sheet):
    try:
        current_headers = sheet.row_values(1)
    except:
        current_headers = []
    
    if not current_headers:
        sheet.append_row(REQUIRED_HEADERS)
        return REQUIRED_HEADERS
    
    missing_cols = [col for col in REQUIRED_HEADERS if col not in current_headers]
    if missing_cols:
        if len(current_headers) + len(missing_cols) > sheet.col_count:
            sheet.resize(cols=len(current_headers) + len(missing_cols) + 5)
        start_col_idx = len(current_headers) + 1
        for i, col_name in enumerate(missing_cols):
            sheet.update_cell(1, start_col_idx + i, col_name)
        return current_headers + missing_cols
    return current_headers

@st.cache_data(ttl=600)
def load_data():
    client = get_sheet_client()
    if not client: return pd.DataFrame()
    try:
        sheet = client.open("Youtube_Test_Local").sheet1
        data = sheet.get_all_records()
        df = pd.DataFrame(data)
        for col in REQUIRED_HEADERS:
            if col not in df.columns:
                df[col] = "" 
        df = df.fillna("")
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

def append_data_to_sheet(json_data):
    client = get_sheet_client()
    if not client: return False, "êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨"
    try:
        sheet = client.open("Youtube_Test_Local").sheet1
        current_headers = check_and_update_headers(sheet)
        if isinstance(json_data, dict): items = [json_data]
        elif isinstance(json_data, list): items = json_data
        else: return False, "JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤."

        rows_to_append = []
        for item in items:
            row = []
            for header in current_headers:
                val = item.get(header, "")
                if isinstance(val, list): val = "\n".join(val)
                row.append(str(val))
            rows_to_append.append(row)
        sheet.append_rows(rows_to_append)
        return True, f"{len(items)}ê±´ ì €ì¥ ì™„ë£Œ!"
    except Exception as e:
        return False, f"ì˜¤ë¥˜: {e}"

# ==========================================
# [í•¨ìˆ˜] Gemini API
# ==========================================
def ask_gemini(query, context, mode="analysis"):
    try:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
        model = genai.GenerativeModel('gemini-2.5-flash')
        today = datetime.datetime.now().strftime("%Y-%m-%d")
        
        if mode == "analysis":
            prompt = f"""
            ë‹¹ì‹ ì€ ìˆ˜ì„ ê¸ˆìœµ íˆ¬ì ì „ëµê°€ì…ë‹ˆë‹¤.
            ì•„ë˜ [ë¶„ì„ ë°ì´í„°]ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.
            [ë¶„ì„ ë°ì´í„°]
            {context}
            [ì§ˆë¬¸]
            {query}
            [ì§€ì¹¨]
            1. 'published_at'ì„ ì°¸ê³ í•˜ë˜ ë‚´ìš©ì€ 'evidence'ì™€ 'implications' ìœ„ì£¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.
            2. ë°˜ë“œì‹œ **"[ìë£Œ N] ì œëª©"** í˜•íƒœë¡œ ì¶œì²˜ë¥¼ ë°íˆì„¸ìš”.
            """
        elif mode == "critique":
            prompt = f"""
            ë‹¹ì‹ ì€ 'ê¸ˆìœµ ë¦¬ìŠ¤í¬ ê´€ë¦¬ì'ì…ë‹ˆë‹¤. (í˜„ì¬: {today})
            ì•„ë˜ ì œê³µëœ [ìƒì„¸ ì›ë³¸ ë°ì´í„°]ë¥¼ ê¼¼ê¼¼íˆ ê²€í† í•˜ì—¬, AIì˜ ë‹µë³€ì„ ë¹„í‰í•˜ì„¸ìš”.
            íŠ¹íˆ ì›ë³¸ ë°ì´í„°ì˜ 'evidence'(ê·¼ê±°)ì™€ 'validity_check'(íƒ€ë‹¹ì„± ê²€í† ) ë‚´ìš©ì„ ì ê·¹ í™œìš©í•˜ì„¸ìš”.

            [ì‚¬ìš©ì ì§ˆë¬¸]
            {query}
            
            [AI ë‹µë³€]
            {context['ai_answer']}
            
            [ìƒì„¸ ì›ë³¸ ë°ì´í„° (ì°¸ê³ ìš©)]
            {context['raw_data']}

            [ì‘ì„± ì–‘ì‹]
            1. ğŸŒŸ **ê¸ì •ì  í‰ê°€:** ë‹µë³€ì˜ ì¥ì .
            2. âš–ï¸ **ë¹„íŒì  ê²€ì¦:** ì›ë³¸ ë°ì´í„°ì˜ 'ê·¼ê±°'ì™€ ë¹„êµí–ˆì„ ë•Œ ê³¼ì¥ë˜ê±°ë‚˜ ëˆ„ë½ëœ ë¦¬ìŠ¤í¬ ì§€ì .
            3. ğŸ’¡ **ì¶”ê°€ ì¸ì‚¬ì´íŠ¸:** ë†“ì¹œ ì‹œì‚¬ì  ë³´ì™„.
            """
        
        if mode == "critique":
            final_prompt = prompt 
        else:
            final_prompt = prompt

        response = model.generate_content(final_prompt)
        return response.text
    except Exception as e:
        return f"AI ì˜¤ë¥˜: {e}"

# ==========================================
# [PAGE] ë°ì´í„° ê´€ë¦¬ í˜ì´ì§€
# ==========================================
def show_db_management_page(df):
    st.header("âš™ï¸ DB ë°ì´í„° ê´€ë¦¬ ì„¼í„°")
    st.info("ì™¸ë¶€ AIë¥¼ ì´ìš©í•´ ì˜ìƒì„ ë¶„ì„í•˜ê³  JSONìœ¼ë¡œ ì €ì¥í•˜ì„¸ìš”.")

    with st.container(border=True):
        st.subheader("ğŸ“ ë°ì´í„° ìˆ˜ë™ ì¶”ê°€")
        st.markdown("##### ğŸ‘‡ ì•„ë˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë³µì‚¬í•˜ì—¬ ChatGPTì—ê²Œ ë³´ë‚´ì„¸ìš”")
        prompt_text = """
ë‹¹ì‹ ì€ ìˆ˜ì„ ê¸ˆìœµ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ìœ„ì˜ ìœ íŠœë¸Œ ë§í¬ì˜ í•´ë‹¹ ì˜ìƒì˜ ë‚´ìš©ì„ ì‹¬ì¸µ ë¶„ì„í•´ì„œ ì•„ë˜ì˜ JSON í¬ë§·ìœ¼ë¡œ ì¶œë ¥í•´ ì¤˜.

[ë¶„ì„ ì§€ì¹¨]
1. ë‹¤ë¥¸ ë§(ì„œë¡ , ì¶”ì„ìƒˆ)ì€ ì ˆëŒ€ í•˜ì§€ ë§ê³  **ì˜¤ì§ JSON ì½”ë“œ ë¸”ë¡**ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
2. 'key_arguments'ì™€ 'evidence'ëŠ” ì§ì„ ì´ë£¨ì–´ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
3. ìˆ˜ì¹˜(%, ê¸ˆì•¡, ë‚ ì§œ)ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
4. íˆ¬ìì ê´€ì ì—ì„œ ì‹¤ì§ˆì ì¸ ë„ì›€ì´ ë˜ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

[JSON í¬ë§·]
{
  "video_id": "ì˜ìƒID (URLì—ì„œ ì¶”ì¶œ, ëª¨ë¥´ë©´ ê³µë€)",
  "url": "ì˜ìƒ ì „ì²´ URL",
  "title": "ì˜ìƒ ì œëª©",
  "channel_name": "ì±„ë„ëª…",
  "published_at": "YYYY-MM-DD (ê²Œì‹œì¼ í•„ìˆ˜)",
  "category": "ì£¼ì‹/ë¶€ë™ì‚°/ì½”ì¸/ê±°ì‹œê²½ì œ ì¤‘ íƒ1 (í•„ìˆ˜)",
  "main_topic": "ì˜ìƒì„ ê´€í†µí•˜ëŠ” í•µì‹¬ ì£¼ì œ (1ë¬¸ì¥)",
  "key_arguments": [
    "í•µì‹¬ ì£¼ì¥ 1",
    "í•µì‹¬ ì£¼ì¥ 2",
    "í•µì‹¬ ì£¼ì¥ 3",
    "í•µì‹¬ ì£¼ì¥ 4"
  ],
  "evidence": [
    "ì£¼ì¥ 1ì— ëŒ€í•œ ê·¼ê±°(ìˆ˜ì¹˜/íŒ©íŠ¸)",
    "ì£¼ì¥ 2ì— ëŒ€í•œ ê·¼ê±°",
    "ì£¼ì¥ 3ì— ëŒ€í•œ ê·¼ê±°",
    "ì£¼ì¥ 4ì— ëŒ€í•œ ê·¼ê±°"
  ],
  "implications": "íˆ¬ììë¥¼ ìœ„í•œ ì‹œì‚¬ì  ë° êµ¬ì²´ì ì¸ ì•¡ì…˜ í”Œëœ",
  "validity_check": "ë…¼ë¦¬ì  íƒ€ë‹¹ì„± ë° ë¹„íŒì  ê²€í† ",
  "sentiment": "ê¸ì •/ë¶€ì •/ì¤‘ë¦½",
  "tags": "í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3, í‚¤ì›Œë“œ4",
  "full_summary": "ì „ì²´ ë‚´ìš© ìƒì„¸ ìš”ì•½ (ì„œë¡ -ë³¸ë¡ -ê²°ë¡ )"
}
        """
        st.code(prompt_text, language="text")
        json_input = st.text_area("JSON ì…ë ¥", height=150)
        if st.button("ğŸ’¾ DBì— ì €ì¥í•˜ê¸°", type="primary", use_container_width=True):
            if json_input.strip():
                try:
                    parsed_json = json.loads(json_input)
                    with st.spinner("ì €ì¥ ì¤‘..."):
                        success, msg = append_data_to_sheet(parsed_json)
                        if success: st.success(msg); st.cache_data.clear(); st.rerun()
                        else: st.error(msg)
                except: st.error("JSON í˜•ì‹ ì˜¤ë¥˜")

    st.divider()
    st.subheader(f"ğŸ—‚ï¸ í˜„ì¬ DB ëª©ë¡ ({len(df)}ê±´)")
    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", use_container_width=True): st.cache_data.clear(); st.rerun()

    if not df.empty and 'title' in df.columns:
        # [ìˆ˜ì • 1] í•µì‹¬ì£¼ì œ í¬í•¨
        cols_to_show = ['title', 'main_topic', 'published_at', 'category']
        valid_cols = [c for c in cols_to_show if c in df.columns]
        
        display_df = df[valid_cols].copy()
        display_df.insert(0, 'No', range(1, len(display_df) + 1))
        
        # [ìˆ˜ì • 2] HTML í…Œì´ë¸” ìŠ¤íƒ€ì¼ë§ (ì¤„ë°”ê¿ˆ ë° ë„ˆë¹„ ì¡°ì •)
        st.markdown("""
        <style>
        .styled-table { width: 100%; border-collapse: collapse; font-size: 14px; }
        .styled-table th { background-color: #f0f2f6; border: 1px solid #e0e0e0; padding: 10px; text-align: center; }
        .styled-table td { border: 1px solid #e0e0e0; padding: 10px; vertical-align: top; }
        
        /* ì»¬ëŸ¼ë³„ ë„ˆë¹„ ì§€ì • (ë¹„ìœ¨ë¡œ ì¡°ì •) */
        .styled-table td:nth-child(1) { width: 5%; text-align: center; font-weight: bold; } /* No */
        .styled-table td:nth-child(2) { width: 30%; word-break: keep-all; } /* ì œëª© (ì¤„ë°”ê¿ˆ í—ˆìš©) */
        .styled-table td:nth-child(3) { width: 45%; word-break: keep-all; } /* í•µì‹¬ì£¼ì œ (ì¤„ë°”ê¿ˆ í—ˆìš©) */
        .styled-table td:nth-child(4) { width: 10%; text-align: center; white-space: nowrap; } /* ê²Œì‹œì¼ (í•œì¤„) */
        .styled-table td:nth-child(5) { width: 10%; text-align: center; white-space: nowrap; } /* ë¶„ë¥˜ (í•œì¤„) */
        </style>
        """, unsafe_allow_html=True)

        # ë°ì´í„°í”„ë ˆì„ì„ HTMLë¡œ ë³€í™˜í•˜ì—¬ ì¶œë ¥
        html = display_df.to_html(index=False, classes='styled-table', escape=True)
        st.markdown(html, unsafe_allow_html=True)
        
    else:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ==========================================
# [PAGE] ì±—ë´‡ í˜ì´ì§€
# ==========================================
def show_chatbot_page(df):
    st.header("ğŸ’¬ AI ê¸ˆìœµ íˆ¬ì ë¹„ì„œ")
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! íˆ¬ì ì „ëµì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”."}]

    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    if st.session_state.messages and st.session_state.messages[-1]["role"] == "assistant":
        if len(st.session_state.messages) > 1:
            st.markdown("---")
            with st.container(border=True):
                col1, col2 = st.columns([0.6, 0.4])
                with col1:
                    st.write("##### ğŸ§ ë‹µë³€ ê²€ì¦")
                    st.caption("AI ë¦¬ìŠ¤í¬ ê´€ë¦¬ìê°€ ì‹¬ì¸µ ë¶„ì„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¹„í‰í•©ë‹ˆë‹¤.")
                with col2:
                    if st.button("ğŸš© ë¹„í‰ ë³´ê¸°", key="critique_btn", type="secondary", use_container_width=True):
                        last_msg = st.session_state.messages[-1]["content"]
                        last_query = st.session_state.messages[-2]["content"]
                        raw_context = st.session_state.get("last_raw_context", "ì›ë³¸ ë°ì´í„° ì—†ìŒ")
                        
                        critique_payload = {
                            "ai_answer": last_msg,
                            "raw_data": raw_context
                        }
                        
                        with st.spinner("ì‹¬ì¸µ ê²€ì¦ ì¤‘..."):
                            critique = ask_gemini(last_query, critique_payload, mode="critique")
                            st.session_state.messages.append({"role": "assistant", "content": f"ğŸ“ **[ì „ë¬¸ê°€ ë¹„í‰ ë¦¬í¬íŠ¸]**\n\n{critique}"})
                            st.rerun()

    if prompt := st.chat_input("ì§ˆë¬¸ ì…ë ¥ (ì˜ˆ: ë°˜ë„ì²´ ì „ë§)"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.rerun()

    if st.session_state.messages[-1]["role"] == "user":
        user_query = st.session_state.messages[-1]["content"]
        
        search_target = ['title', 'main_topic', 'full_summary', 'category', 'tags']
        valid_cols = [col for col in search_target if col in df.columns]
        
        context_text = ""
        full_raw_data = "" 
        
        if not df.empty and valid_cols:
            mask = df[valid_cols].astype(str).apply(lambda x: x.str.contains(user_query, case=False).any(), axis=1)
            filtered_df = df[mask]
            target_df = filtered_df if not filtered_df.empty else df.tail(5)
            
            for i, (idx, row) in enumerate(target_df.iterrows(), 1):
                real_db_no = idx + 1
                
                context_text += f"""
                [ìë£Œ {real_db_no}]
                - ì œëª©: {row.get('title')} (ë‚ ì§œ: {row.get('published_at')})
                - ìš”ì•½: {row.get('full_summary')}
                - ê·¼ê±°: {row.get('evidence')}
                """
                
                full_raw_data += f"""
                === [ìë£Œ {real_db_no} ìƒì„¸] ===
                ì œëª©: {row.get('title')}
                ì±„ë„: {row.get('channel_name')}
                ë‚ ì§œ: {row.get('published_at')}
                ì£¼ì œ: {row.get('main_topic')}
                ì£¼ì¥: {row.get('key_arguments')}
                ê·¼ê±°: {row.get('evidence')}
                ì‹œì‚¬ì : {row.get('implications')}
                íƒ€ë‹¹ì„±: {row.get('validity_check')}
                =============================
                """
                
            st.session_state["last_raw_context"] = full_raw_data
            
        else:
            context_text = "ê´€ë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            st.session_state["last_raw_context"] = "ê´€ë ¨ ë°ì´í„° ì—†ìŒ"

        with st.chat_message("assistant"):
            with st.spinner("ë¶„ì„ ì¤‘..."):
                response = ask_gemini(user_query, context_text, mode="analysis")
                st.write(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
                st.rerun()

# ==========================================
# [Main] ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ==========================================
def main():
    df = load_data()
    st.title("ğŸ“± ê¸ˆìœµ ì¸ì‚¬ì´íŠ¸ AI Pro")
    col1, col2, col3 = st.columns([1, 8, 1])
    with col2:
        page = st.radio("ë©”ë‰´", ["ğŸ’¬ AI íˆ¬ì ë¹„ì„œ", "âš™ï¸ DB ë°ì´í„° ê´€ë¦¬"], index=0, horizontal=True, label_visibility="collapsed")
    st.divider()
    if page == "âš™ï¸ DB ë°ì´í„° ê´€ë¦¬": show_db_management_page(df)
    else: show_chatbot_page(df)

if __name__ == "__main__":
    main()
