import streamlit as st
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import google.generativeai as genai
import json
import datetime

# ==========================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==========================================
st.set_page_config(page_title="ê¸ˆìœµ ì¸ì‚¬ì´íŠ¸ AI Pro (Ver 4.5)", page_icon="ğŸ“ˆ", layout="wide")

# ==========================================
# [í•¨ìˆ˜] êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
# ==========================================
def get_sheet_client():
    if "gcp_service_account" not in st.secrets:
        st.error("Secrets ì„¤ì •(gcp_service_account)ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return None
    json_creds = dict(st.secrets["gcp_service_account"])
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_dict(json_creds, scope)
    client = gspread.authorize(creds)
    return client

# DB ìŠ¤í‚¤ë§ˆ (14ê°œ ì»¬ëŸ¼)
REQUIRED_HEADERS = [
    'video_id', 'url', 'title', 'channel_name', 'published_at', 
    'category', 'main_topic', 'key_arguments', 'evidence', 
    'implications', 'validity_check', 'sentiment', 'tags', 'full_summary'
]

def check_and_update_headers(sheet):
    try:
        current_headers = sheet.row_values(1)
    except:
        current_headers = []
    
    if not current_headers:
        sheet.append_row(REQUIRED_HEADERS)
        return REQUIRED_HEADERS
    
    missing_cols = [col for col in REQUIRED_HEADERS if col not in current_headers]
    if missing_cols:
        if len(current_headers) + len(missing_cols) > sheet.col_count:
            sheet.resize(cols=len(current_headers) + len(missing_cols) + 5)
        start_col_idx = len(current_headers) + 1
        for i, col_name in enumerate(missing_cols):
            sheet.update_cell(1, start_col_idx + i, col_name)
        return current_headers + missing_cols
    return current_headers

@st.cache_data(ttl=600)
def load_data():
    client = get_sheet_client()
    if not client: return pd.DataFrame()
    try:
        sheet = client.open("Youtube_Test_Local").sheet1
        data = sheet.get_all_records()
        df = pd.DataFrame(data)
        for col in REQUIRED_HEADERS:
            if col not in df.columns:
                df[col] = "" 
        df = df.fillna("")
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

def append_data_to_sheet(json_data):
    client = get_sheet_client()
    if not client: return False, "êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨"
    try:
        sheet = client.open("Youtube_Test_Local").sheet1
        current_headers = check_and_update_headers(sheet)
        if isinstance(json_data, dict): items = [json_data]
        elif isinstance(json_data, list): items = json_data
        else: return False, "JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤."

        rows_to_append = []
        for item in items:
            row = []
            for header in current_headers:
                val = item.get(header, "")
                if isinstance(val, list): val = "\n".join(val)
                row.append(str(val))
            rows_to_append.append(row)
        sheet.append_rows(rows_to_append)
        return True, f"{len(items)}ê±´ ì €ì¥ ì™„ë£Œ!"
    except Exception as e:
        return False, f"ì˜¤ë¥˜: {e}"

# ==========================================
# [í•¨ìˆ˜] Gemini API
# ==========================================
def ask_gemini(query, context, mode="analysis"):
    try:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
        model = genai.GenerativeModel('gemini-2.5-flash')
        today = datetime.datetime.now().strftime("%Y-%m-%d")
        
        if mode == "analysis":
            prompt = f"""
            ë‹¹ì‹ ì€ ìˆ˜ì„ ê¸ˆìœµ íˆ¬ì ì „ëµê°€ì…ë‹ˆë‹¤.
            ì•„ë˜ [ë¶„ì„ ë°ì´í„°]ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.
            [ë¶„ì„ ë°ì´í„°]
            {context}
            [ì§ˆë¬¸]
            {query}
            [ì§€ì¹¨]
            1. 'published_at'ì„ ì°¸ê³ í•˜ë˜ ë‚´ìš©ì€ 'evidence'ì™€ 'implications' ìœ„ì£¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.
            2. ë°˜ë“œì‹œ **"[ìë£Œ N] ì œëª©"** í˜•íƒœë¡œ ì¶œì²˜ë¥¼ ë°íˆì„¸ìš”.
            """
        elif mode == "critique":
            # [ìˆ˜ì •ë¨] ë¹„í‰ê°€ì—ê²Œ ëª¨ë“  ì •ë³´ë¥¼ ë‹¤ ì œê³µí•œë‹¤ëŠ” ê²ƒì„ ëª…ì‹œ
            prompt = f"""
            ë‹¹ì‹ ì€ 'ê¸ˆìœµ ë¦¬ìŠ¤í¬ ê´€ë¦¬ì'ì…ë‹ˆë‹¤. (í˜„ì¬: {today})
            ì•„ë˜ ì œê³µëœ [ìƒì„¸ ì›ë³¸ ë°ì´í„°]ë¥¼ ê¼¼ê¼¼íˆ ê²€í† í•˜ì—¬, AIì˜ ë‹µë³€ì„ ë¹„í‰í•˜ì„¸ìš”.
            íŠ¹íˆ ì›ë³¸ ë°ì´í„°ì˜ 'evidence'(ê·¼ê±°)ì™€ 'validity_check'(íƒ€ë‹¹ì„± ê²€í† ) ë‚´ìš©ì„ ì ê·¹ í™œìš©í•˜ì„¸ìš”.

            [ì‚¬ìš©ì ì§ˆë¬¸]
            {query}
            
            [AI ë‹µë³€]
            {context['ai_answer']}
            
            [ìƒì„¸ ì›ë³¸ ë°ì´í„° (ì°¸ê³ ìš©)]
            {context['raw_data']}

            [ì‘ì„± ì–‘ì‹]
            1. ğŸŒŸ **ê¸ì •ì  í‰ê°€:** ë‹µë³€ì˜ ì¥ì .
            2. âš–ï¸ **ë¹„íŒì  ê²€ì¦:** ì›ë³¸ ë°ì´í„°ì˜ 'ê·¼ê±°'ì™€ ë¹„êµí–ˆì„ ë•Œ ê³¼ì¥ë˜ê±°ë‚˜ ëˆ„ë½ëœ ë¦¬ìŠ¤í¬ ì§€ì .
            3. ğŸ’¡ **ì¶”ê°€ ì¸ì‚¬ì´íŠ¸:** ë†“ì¹œ ì‹œì‚¬ì  ë³´ì™„.
            """
        
        # ë¹„í‰ ëª¨ë“œì¼ ë•ŒëŠ” contextê°€ ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ ì²˜ë¦¬ ë°©ì‹ ë¶„ê¸°
        if mode == "critique":
            final_prompt = prompt 
        else:
            final_prompt = prompt

        response = model.generate_content(final_prompt)
        return response.text
    except Exception as e:
        return f"AI ì˜¤ë¥˜: {e}"

# ==========================================
# [PAGE] ë°ì´í„° ê´€ë¦¬ í˜ì´ì§€
# ==========================================
def show_db_management_page(df):
    st.header("âš™ï¸ DB ë°ì´í„° ê´€ë¦¬ ì„¼í„°")
    st.info("ì™¸ë¶€ AIë¥¼ ì´ìš©í•´ ì˜ìƒì„ ë¶„ì„í•˜ê³  JSONìœ¼ë¡œ ì €ì¥í•˜ì„¸ìš”.")

    with st.container(border=True):
        st.subheader("ğŸ“ ë°ì´í„° ìˆ˜ë™ ì¶”ê°€")
        st.markdown("##### ğŸ‘‡ ì•„ë˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë³µì‚¬í•˜ì—¬ ChatGPTì—ê²Œ ë³´ë‚´ì„¸ìš”")
        prompt_text = """
ë‹¹ì‹ ì€ ìˆ˜ì„ ê¸ˆìœµ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ ì˜ìƒ(ë˜ëŠ” í…ìŠ¤íŠ¸)ì˜ ë‚´ìš©ì„ ì‹¬ì¸µ ë¶„ì„í•˜ì—¬ ì•„ë˜ì˜ JSON í¬ë§·ìœ¼ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.

[JSON í¬ë§·]
{
  "video_id": "", "url": "", "title": "ì˜ìƒ ì œëª©", "channel_name": "ì±„ë„ëª…",
  "published_at": "YYYY-MM-DD", "category": "ì£¼ì‹/ë¶€ë™ì‚°/ì½”ì¸/ê±°ì‹œê²½ì œ",
  "main_topic": "í•µì‹¬ì£¼ì œ", "key_arguments": ["ì£¼ì¥1", "ì£¼ì¥2"],
  "evidence": ["ê·¼ê±°1", "ê·¼ê±°2"], "implications": "ì‹œì‚¬ì ",
  "validity_check": "íƒ€ë‹¹ì„± ê²€í† ", "sentiment": "ê¸ì •/ë¶€ì •",
  "tags": "íƒœê·¸1, íƒœê·¸2", "full_summary": "ìš”ì•½"
}
        """
        st.code(prompt_text, language="text")
        json_input = st.text_area("JSON ì…ë ¥", height=150)
        if st.button("ğŸ’¾ DBì— ì €ì¥í•˜ê¸°", type="primary", use_container_width=True):
            if json_input.strip():
                try:
                    parsed_json = json.loads(json_input)
                    with st.spinner("ì €ì¥ ì¤‘..."):
                        success, msg = append_data_to_sheet(parsed_json)
                        if success: st.success(msg); st.cache_data.clear(); st.rerun()
                        else: st.error(msg)
                except: st.error("JSON í˜•ì‹ ì˜¤ë¥˜")

    st.divider()
    st.subheader(f"ğŸ—‚ï¸ í˜„ì¬ DB ëª©ë¡ ({len(df)}ê±´)")
    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", use_container_width=True): st.cache_data.clear(); st.rerun()

    if not df.empty and 'title' in df.columns:
        # [ìˆ˜ì • 1] í•µì‹¬ì£¼ì œ(main_topic) ì¶”ê°€ ë° ì»¬ëŸ¼ ì„¤ì • ìµœì í™”
        cols_to_show = ['title', 'main_topic', 'published_at', 'category']
        valid_cols = [c for c in cols_to_show if c in df.columns]
        
        display_df = df[valid_cols].copy()
        display_df.insert(0, 'No', range(1, len(display_df) + 1))
        
        # column_configë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„± ê°œì„  (í…ìŠ¤íŠ¸ ì˜ë¦¼ ë°©ì§€)
        st.dataframe(
            display_df, 
            use_container_width=True, 
            height=500, 
            hide_index=True,
            column_config={
                "No": st.column_config.TextColumn("No", width="small"),
                "title": st.column_config.TextColumn("ì˜ìƒ ì œëª©", width="large"),
                "main_topic": st.column_config.TextColumn("í•µì‹¬ ì£¼ì œ", width="large"), # í•µì‹¬ì£¼ì œ ë„“ê²Œ
                "published_at": st.column_config.TextColumn("ê²Œì‹œì¼", width="small"),
                "category": st.column_config.TextColumn("ë¶„ë¥˜", width="small")
            }
        )
    else:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ==========================================
# [PAGE] ì±—ë´‡ í˜ì´ì§€
# ==========================================
def show_chatbot_page(df):
    st.header("ğŸ’¬ AI ê¸ˆìœµ íˆ¬ì ë¹„ì„œ")
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! íˆ¬ì ì „ëµì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”."}]

    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    if st.session_state.messages and st.session_state.messages[-1]["role"] == "assistant":
        if len(st.session_state.messages) > 1:
            st.markdown("---")
            with st.container(border=True):
                col1, col2 = st.columns([0.6, 0.4])
                with col1:
                    st.write("##### ğŸ§ ë‹µë³€ ê²€ì¦")
                    st.caption("AI ë¦¬ìŠ¤í¬ ê´€ë¦¬ìê°€ ì‹¬ì¸µ ë¶„ì„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¹„í‰í•©ë‹ˆë‹¤.")
                with col2:
                    if st.button("ğŸš© ë¹„í‰ ë³´ê¸°", key="critique_btn", type="secondary", use_container_width=True):
                        # [ìˆ˜ì • 2] ë¹„í‰ê°€ì—ê²Œ ì›ë³¸ ë°ì´í„°(Raw Data)ë¥¼ í†µì§¸ë¡œ ë„˜ê¹€
                        last_msg = st.session_state.messages[-1]["content"]
                        last_query = st.session_state.messages[-2]["content"]
                        raw_context = st.session_state.get("last_raw_context", "ì›ë³¸ ë°ì´í„° ì—†ìŒ")
                        
                        critique_payload = {
                            "ai_answer": last_msg,
                            "raw_data": raw_context
                        }
                        
                        with st.spinner("ì‹¬ì¸µ ê²€ì¦ ì¤‘..."):
                            critique = ask_gemini(last_query, critique_payload, mode="critique")
                            st.session_state.messages.append({"role": "assistant", "content": f"ğŸ“ **[ì „ë¬¸ê°€ ë¹„í‰ ë¦¬í¬íŠ¸]**\n\n{critique}"})
                            st.rerun()

    if prompt := st.chat_input("ì§ˆë¬¸ ì…ë ¥ (ì˜ˆ: ë°˜ë„ì²´ ì „ë§)"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.rerun()

    if st.session_state.messages[-1]["role"] == "user":
        user_query = st.session_state.messages[-1]["content"]
        
        search_target = ['title', 'main_topic', 'full_summary', 'category', 'tags']
        valid_cols = [col for col in search_target if col in df.columns]
        
        context_text = ""
        full_raw_data = "" # ë¹„í‰ê°€ë¥¼ ìœ„í•œ ìƒì„¸ ì›ë³¸ ë°ì´í„°
        
        if not df.empty and valid_cols:
            mask = df[valid_cols].astype(str).apply(lambda x: x.str.contains(user_query, case=False).any(), axis=1)
            filtered_df = df[mask]
            target_df = filtered_df if not filtered_df.empty else df.tail(5)
            
            for i, (idx, row) in enumerate(target_df.iterrows(), 1):
                real_db_no = idx + 1
                
                # ë¶„ì„ê°€ìš© ìš”ì•½ ì •ë³´
                context_text += f"""
                [ìë£Œ {real_db_no}]
                - ì œëª©: {row.get('title')} (ë‚ ì§œ: {row.get('published_at')})
                - ìš”ì•½: {row.get('full_summary')}
                - ê·¼ê±°: {row.get('evidence')}
                """
                
                # ë¹„í‰ê°€ìš© ìƒì„¸ ì •ë³´ (ëª¨ë“  ì»¬ëŸ¼ í¬í•¨)
                full_raw_data += f"""
                === [ìë£Œ {real_db_no} ìƒì„¸] ===
                ì œëª©: {row.get('title')}
                ì±„ë„: {row.get('channel_name')}
                ë‚ ì§œ: {row.get('published_at')}
                ì£¼ì œ: {row.get('main_topic')}
                ì£¼ì¥: {row.get('key_arguments')}
                ê·¼ê±°: {row.get('evidence')}
                ì‹œì‚¬ì : {row.get('implications')}
                íƒ€ë‹¹ì„±: {row.get('validity_check')}
                =============================
                """
                
            # ì„¸ì…˜ì— ì›ë³¸ ë°ì´í„° ì €ì¥ (ë¹„í‰ ì‹œ ì‚¬ìš©)
            st.session_state["last_raw_context"] = full_raw_data
            
        else:
            context_text = "ê´€ë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            st.session_state["last_raw_context"] = "ê´€ë ¨ ë°ì´í„° ì—†ìŒ"

        with st.chat_message("assistant"):
            with st.spinner("ë¶„ì„ ì¤‘..."):
                response = ask_gemini(user_query, context_text, mode="analysis")
                st.write(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
                st.rerun()

# ==========================================
# [Main] ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ==========================================
def main():
    df = load_data()
    st.title("ğŸ“± ê¸ˆìœµ ì¸ì‚¬ì´íŠ¸ AI Pro")
    col1, col2, col3 = st.columns([1, 8, 1])
    with col2:
        page = st.radio("ë©”ë‰´", ["ğŸ’¬ AI íˆ¬ì ë¹„ì„œ", "âš™ï¸ DB ë°ì´í„° ê´€ë¦¬"], index=0, horizontal=True, label_visibility="collapsed")
    st.divider()
    if page == "âš™ï¸ DB ë°ì´í„° ê´€ë¦¬": show_db_management_page(df)
    else: show_chatbot_page(df)

if __name__ == "__main__":
    main()
