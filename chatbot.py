import streamlit as st
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import google.generativeai as genai
import json
import datetime

# ==========================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==========================================
st.set_page_config(page_title="ê¸ˆìœµ ì¸ì‚¬ì´íŠ¸ AI Pro (Ver 4.3)", page_icon="ğŸ“ˆ", layout="wide")

# ==========================================
# [í•¨ìˆ˜] êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
# ==========================================
def get_sheet_client():
    if "gcp_service_account" not in st.secrets:
        st.error("Secrets ì„¤ì •(gcp_service_account)ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return None
    json_creds = dict(st.secrets["gcp_service_account"])
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_dict(json_creds, scope)
    client = gspread.authorize(creds)
    return client

# [ì¤‘ìš”] DB ìŠ¤í‚¤ë§ˆ ì •ì˜ (ìˆ˜ì§‘ ë´‡ê³¼ ë™ì¼í•˜ê²Œ ë§ì¶¤)
REQUIRED_HEADERS = [
    'video_id', 'url', 'title', 'channel_name', 'published_at', 
    'view_count', 'category', 'main_topic', 'key_arguments', 
    'evidence', 'implications', 'validity_check', 'sentiment', 
    'tags', 'full_summary'
]

def check_and_update_headers(sheet):
    try:
        current_headers = sheet.row_values(1)
    except:
        current_headers = []
    
    if not current_headers:
        sheet.append_row(REQUIRED_HEADERS)
        return REQUIRED_HEADERS
    
    missing_cols = [col for col in REQUIRED_HEADERS if col not in current_headers]
    if missing_cols:
        if len(current_headers) + len(missing_cols) > sheet.col_count:
            sheet.resize(cols=len(current_headers) + len(missing_cols) + 5)
        start_col_idx = len(current_headers) + 1
        for i, col_name in enumerate(missing_cols):
            sheet.update_cell(1, start_col_idx + i, col_name)
        return current_headers + missing_cols
    return current_headers

@st.cache_data(ttl=600)
def load_data():
    client = get_sheet_client()
    if not client: return pd.DataFrame()
    try:
        sheet = client.open("Youtube_Test_Local").sheet1
        data = sheet.get_all_records()
        df = pd.DataFrame(data)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ê°’ìœ¼ë¡œ ì±„ì›€
        for col in REQUIRED_HEADERS:
            if col not in df.columns:
                df[col] = "" 
        df = df.fillna("")
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

def append_data_to_sheet(json_data):
    client = get_sheet_client()
    if not client: return False, "êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨"
    try:
        sheet = client.open("Youtube_Test_Local").sheet1
        current_headers = check_and_update_headers(sheet)
        
        if isinstance(json_data, dict): items = [json_data]
        elif isinstance(json_data, list): items = json_data
        else: return False, "JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤."

        rows_to_append = []
        for item in items:
            row = []
            for header in current_headers:
                # ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ë°ì´í„°ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
                val = item.get(header, "")
                if isinstance(val, list):
                    val = "\n".join(val)
                row.append(str(val))
            rows_to_append.append(row)
            
        sheet.append_rows(rows_to_append)
        return True, f"{len(items)}ê±´ ì €ì¥ ì™„ë£Œ!"
    except Exception as e:
        return False, f"ì˜¤ë¥˜: {e}"

# ==========================================
# [í•¨ìˆ˜] Gemini API
# ==========================================
def ask_gemini(query, context, mode="analysis"):
    try:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
        model = genai.GenerativeModel('gemini-2.5-flash')
        today = datetime.datetime.now().strftime("%Y-%m-%d")
        
        if mode == "analysis":
            prompt = f"""
            ë‹¹ì‹ ì€ ìˆ˜ì„ ê¸ˆìœµ íˆ¬ì ì „ëµê°€ì…ë‹ˆë‹¤.
            ì•„ë˜ [ë¶„ì„ ë°ì´í„°]ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.
            [ë¶„ì„ ë°ì´í„°]
            {context}
            [ì§ˆë¬¸]
            {query}
            [ì§€ì¹¨]
            1. 'published_at'(ê²Œì‹œì¼)ì´ ìˆë‹¤ë©´ ì°¸ê³ í•˜ë˜, ì—†ìœ¼ë©´ ë‚´ìš©ì˜ ë…¼ë¦¬ì„±ì— ì§‘ì¤‘í•˜ì„¸ìš”.
            2. 'evidence'(ê·¼ê±°)ì™€ 'implications'(ì‹œì‚¬ì )ì„ ì ê·¹ í™œìš©í•˜ì—¬ ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.
            3. **ì¶œì²˜ í‘œê¸° í•„ìˆ˜:** ì£¼ì¥ì˜ ê·¼ê±°ê°€ ë˜ëŠ” ìë£Œë¥¼ ì¸ìš©í•  ë•ŒëŠ” ë°˜ë“œì‹œ **"[ìë£Œ N] ì œëª©"**ê³¼ ê°™ì´ ì¶œì²˜ë¥¼ ëª…í™•íˆ ë°íˆì„¸ìš”.
            """
        elif mode == "critique":
            prompt = f"""
            ë‹¹ì‹ ì€ 'ê¸ˆìœµ ë¦¬ìŠ¤í¬ ê´€ë¦¬ì'ì…ë‹ˆë‹¤.
            í˜„ì¬ ì‹œì ì€ {today}ì…ë‹ˆë‹¤. ì´ ë‚ ì§œëŠ” ë‹¹ì‹ ì´ í˜„ì¬ì— ìˆë‹¤ëŠ” ì¸ì‹ì˜ ê¸°ì¤€ì¼ ë¿ì…ë‹ˆë‹¤.
            DB ìë£Œì— 'published_at'ì´ ì—†ë‹¤ë©´ ì‹œì˜ì„±ì„ ë¬¸ì œ ì‚¼ì§€ ë§ê³ , ë…¼ë¦¬ì˜ íƒ€ë‹¹ì„±ì„ í‰ê°€í•˜ì„¸ìš”.
            
            ì•„ë˜ AI ë‹µë³€ì„ ê²€í† í•˜ê³  ë‹¤ìŒ 3ê°€ì§€ í•­ëª©ìœ¼ë¡œ ë¹„í‰ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

            [ì‚¬ìš©ì ì§ˆë¬¸]
            {query}
            [AI ë‹µë³€]
            {context}

            [ì‘ì„± ì–‘ì‹]
            1. ğŸŒŸ **ê¸ì •ì  í‰ê°€ (Good Points):** - ì´ ë‹µë³€ì´ ê°€ì§„ ì¥ì ê³¼ ê°€ì¹˜ë¥¼ ì–¸ê¸‰í•˜ì„¸ìš”.
            2. âš–ï¸ **ë¹„íŒì  ê²€ì¦ (Critical Review):** - ê°ê´€ì ì¸ ê²½ì œ ë°ì´í„°ë‚˜ ë°˜ëŒ€ ë…¼ë¦¬ë¥¼ ë“¤ì–´ ë¹„íŒí•˜ì„¸ìš”.
            3. ğŸ’¡ **ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ (Key Implications):** - ë‹µë³€ì—ì„œ ë‹¤ë£¨ì§€ ì•Šì€ ì¶”ê°€ ì‹œì‚¬ì ì„ ë„ì¶œí•˜ì„¸ìš”.
            """
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"AI ì˜¤ë¥˜: {e}"

# ==========================================
# [PAGE] ë°ì´í„° ê´€ë¦¬ í˜ì´ì§€
# ==========================================
def show_db_management_page(df):
    st.header("âš™ï¸ DB ë°ì´í„° ê´€ë¦¬ ì„¼í„°")
    st.info("ì™¸ë¶€ AI(ChatGPT, Gemini ë“±)ë¥¼ ì´ìš©í•´ ì˜ìƒì„ ë¶„ì„í•˜ê³  JSONìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•˜ì„¸ìš”.")

    with st.container(border=True):
        st.subheader("ğŸ“ ë°ì´í„° ìˆ˜ë™ ì¶”ê°€")
        st.markdown("##### ğŸ‘‡ ì•„ë˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë³µì‚¬í•˜ì—¬ ChatGPTì—ê²Œ ë³´ë‚´ì„¸ìš”")
        
        # [ìˆ˜ì •ë¨] ì‚¬ìš©ìë‹˜ì´ ì œê³µí•œ ìµœì¢… í”„ë¡¬í”„íŠ¸ ì ìš©
        prompt_text = """
ë‹¹ì‹ ì€ ìˆ˜ì„ ê¸ˆìœµ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ ì˜ìƒ(ë˜ëŠ” í…ìŠ¤íŠ¸)ì˜ ë‚´ìš©ì„ ì‹¬ì¸µ ë¶„ì„í•˜ì—¬ ì•„ë˜ì˜ JSON í¬ë§·ìœ¼ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.

[ë¶„ì„ ì§€ì¹¨]
1. ë‹¤ë¥¸ ë§(ì„œë¡ , ì¶”ì„ìƒˆ)ì€ ì ˆëŒ€ í•˜ì§€ ë§ê³  **ì˜¤ì§ JSON ì½”ë“œ ë¸”ë¡**ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
2. 'key_arguments'ì™€ 'evidence'ëŠ” ì§ì„ ì´ë£¨ì–´ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
3. ìˆ˜ì¹˜(%, ê¸ˆì•¡, ë‚ ì§œ)ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
4. íˆ¬ìì ê´€ì ì—ì„œ ì‹¤ì§ˆì ì¸ ë„ì›€ì´ ë˜ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

[JSON í¬ë§·]
{
  "video_id": "ì˜ìƒID (URLì—ì„œ ì¶”ì¶œ, ëª¨ë¥´ë©´ ê³µë€)",
  "url": "ì˜ìƒ ì „ì²´ URL",
  "title": "ì˜ìƒ ì œëª©",
  "channel_name": "ì±„ë„ëª…",
  "published_at": "YYYY-MM-DD (ê²Œì‹œì¼ í•„ìˆ˜)",
  "category": "ì£¼ì‹/ë¶€ë™ì‚°/ì½”ì¸/ê±°ì‹œê²½ì œ ì¤‘ íƒ1 (í•„ìˆ˜)",
  "main_topic": "ì˜ìƒì„ ê´€í†µí•˜ëŠ” í•µì‹¬ ì£¼ì œ (1ë¬¸ì¥)",
  "key_arguments": ["í•µì‹¬ ì£¼ì¥ 1", "í•µì‹¬ ì£¼ì¥ 2", "í•µì‹¬ ì£¼ì¥ 3", "í•µì‹¬ ì£¼ì¥ 4"],
  "evidence": ["ì£¼ì¥ 1ì— ëŒ€í•œ ê·¼ê±°", "ì£¼ì¥ 2ì— ëŒ€í•œ ê·¼ê±°", "ì£¼ì¥ 3ì— ëŒ€í•œ ê·¼ê±°", "ì£¼ì¥ 4ì— ëŒ€í•œ ê·¼ê±°"],
  "implications": "íˆ¬ììë¥¼ ìœ„í•œ ì‹œì‚¬ì  ë° êµ¬ì²´ì ì¸ ì•¡ì…˜ í”Œëœ",
  "validity_check": "ë…¼ë¦¬ì  íƒ€ë‹¹ì„± ë° ë¹„íŒì  ê²€í† ",
  "sentiment": "ê¸ì •/ë¶€ì •/ì¤‘ë¦½",
  "tags": "í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3, í‚¤ì›Œë“œ4",
  "full_summary": "ì „ì²´ ë‚´ìš© ìƒì„¸ ìš”ì•½ (ì„œë¡ -ë³¸ë¡ -ê²°ë¡ )"
}
        """
        st.code(prompt_text, language="text")
        
        json_input = st.text_area("JSON ì…ë ¥", height=200, placeholder='[{"title": "...", "published_at": "2024-01-01"}]')
        
        if st.button("ğŸ’¾ DBì— ì €ì¥í•˜ê¸°", key="save_btn_page", type="primary", use_container_width=True):
            if not json_input.strip():
                st.warning("ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            else:
                try:
                    parsed_json = json.loads(json_input)
                    with st.spinner("ì €ì¥ ì¤‘..."):
                        success, msg = append_data_to_sheet(parsed_json)
                        if success:
                            st.success(msg)
                            st.cache_data.clear()
                            st.rerun()
                        else:
                            st.error(msg)
                except json.JSONDecodeError:
                    st.error("ì˜ëª»ëœ JSON í˜•ì‹ì…ë‹ˆë‹¤.")

    st.divider()

    st.subheader(f"ğŸ—‚ï¸ í˜„ì¬ DB ëª©ë¡ ({len(df)}ê±´)")
    if st.button("ğŸ”„ ëª©ë¡ ìƒˆë¡œê³ ì¹¨", use_container_width=True):
        st.cache_data.clear()
        st.rerun()

    if not df.empty and 'title' in df.columns:
        # ë³´ì—¬ì¤„ ì»¬ëŸ¼ ì„ íƒ
        cols_to_show = ['title', 'published_at', 'category']
        valid_cols = [c for c in cols_to_show if c in df.columns]
        
        display_df = df[valid_cols].copy()
        display_df.insert(0, 'No', range(1, len(display_df) + 1))
        st.dataframe(display_df, use_container_width=True, height=500, hide_index=True)
    else:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ==========================================
# [PAGE] ì±—ë´‡ í˜ì´ì§€
# ==========================================
def show_chatbot_page(df):
    st.header("ğŸ’¬ AI ê¸ˆìœµ íˆ¬ì ë¹„ì„œ")
    
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! íˆ¬ì ì „ëµì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”."}]

    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    if st.session_state.messages and st.session_state.messages[-1]["role"] == "assistant":
        if len(st.session_state.messages) > 1:
            st.markdown("---")
            with st.container(border=True):
                col1, col2 = st.columns([0.6, 0.4])
                with col1:
                    st.write("##### ğŸ§ ë‹µë³€ ê²€ì¦")
                    st.caption("AI ë¦¬ìŠ¤í¬ ê´€ë¦¬ìì˜ ë¹„í‰ì„ ë“¤ì–´ë³´ì„¸ìš”.")
                with col2:
                    if st.button("ğŸš© ë¹„í‰ ë³´ê¸°", key="critique_btn_main", type="secondary", use_container_width=True):
                        last_msg = st.session_state.messages[-1]["content"]
                        last_query = st.session_state.messages[-2]["content"]
                        with st.spinner("3ë‹¨ê³„ ê²€ì¦ ì¤‘..."):
                            critique = ask_gemini(last_query, last_msg, mode="critique")
                            st.session_state.messages.append({"role": "assistant", "content": f"ğŸ“ **[ì „ë¬¸ê°€ ë¹„í‰ ë¦¬í¬íŠ¸]**\n\n{critique}"})
                            st.rerun()

    if prompt := st.chat_input("ì§ˆë¬¸ ì…ë ¥ (ì˜ˆ: ë¹„íŠ¸ì½”ì¸ ì „ë§)"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.rerun()

    if st.session_state.messages[-1]["role"] == "user":
        user_query = st.session_state.messages[-1]["content"]
        
        # ê²€ìƒ‰ ëŒ€ìƒ ì»¬ëŸ¼ í™•ì¥
        search_target = ['title', 'main_topic', 'full_summary', 'category', 'tags']
        valid_cols = [col for col in search_target if col in df.columns]
        
        context_text = ""
        if not df.empty and valid_cols:
            mask = df[valid_cols].astype(str).apply(lambda x: x.str.contains(user_query, case=False).any(), axis=1)
            filtered_df = df[mask]
            target_df = filtered_df if not filtered_df.empty else df.tail(5)
            
            for i, (idx, row) in enumerate(target_df.iterrows(), 1):
                real_db_no = idx + 1
                # [ì¤‘ìš”] ì±—ë´‡ì—ê²Œ í’ë¶€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ë„ë¡ í¬ë§· ë³€ê²½
                context_text += f"""
                [ìë£Œ {real_db_no}]
                - ì œëª©: {row.get('title')} (ë‚ ì§œ: {row.get('published_at')})
                - ì±„ë„: {row.get('channel_name')}
                - í•µì‹¬ì£¼ì œ: {row.get('main_topic')}
                - ìš”ì•½: {row.get('full_summary')}
                - ê·¼ê±°(Evidence): {row.get('evidence')}
                - ì‹œì‚¬ì (Implications): {row.get('implications')}
                - íƒ€ë‹¹ì„±ê²€í† : {row.get('validity_check')}
                
                """
        else:
            context_text = "ê´€ë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        with st.chat_message("assistant"):
            with st.spinner("ì‹¬ì¸µ ë¶„ì„ ì¤‘..."):
                response = ask_gemini(user_query, context_text, mode="analysis")
                st.write(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
                st.rerun()

# ==========================================
# [Main] ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ==========================================
def main():
    df = load_data()
    st.title("ğŸ“± ê¸ˆìœµ ì¸ì‚¬ì´íŠ¸ AI Pro")

    col1, col2, col3 = st.columns([1, 8, 1])
    with col2:
        page = st.radio("ë©”ë‰´ ì„ íƒ", ["ğŸ’¬ AI íˆ¬ì ë¹„ì„œ", "âš™ï¸ DB ë°ì´í„° ê´€ë¦¬"], index=0, horizontal=True, label_visibility="collapsed")
    
    st.divider()

    if page == "âš™ï¸ DB ë°ì´í„° ê´€ë¦¬":
        show_db_management_page(df)
    else:
        show_chatbot_page(df)

if __name__ == "__main__":
    main()
